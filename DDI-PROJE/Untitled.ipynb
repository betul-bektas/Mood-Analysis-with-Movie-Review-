{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19999 entries, 1 to 19999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   yorum   19999 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 312.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yorum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bu filmin katıldığı festivaller ödüllerini fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>çok komik bir film ya izlediğim en iyi komedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harbiden çooooooook iyiydi herkesin dediği gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hayaller çok geniştir ve insanlar hayallerini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>o kadar sıcak ve samimi bir filmki tebrik etm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               yorum\n",
       "1   Bu filmin katıldığı festivaller ödüllerini fi...\n",
       "2   çok komik bir film ya izlediğim en iyi komedi...\n",
       "3   harbiden çooooooook iyiydi herkesin dediği gi...\n",
       "4   hayaller çok geniştir ve insanlar hayallerini...\n",
       "5   o kadar sıcak ve samimi bir filmki tebrik etm..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veri setinin eklenip başlığının belirlenmesi\n",
    "column = ['yorum']\n",
    "df = pd.read_csv('yorumlar.csv', encoding ='iso-8859-9', sep='\"')\n",
    "df.columns=column\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri setindeki Türkçe dolgu kelimelerinin kaldırılması\n",
    "def remove_stopwords(df_fon):\n",
    "    stopwords = open('turkce-stop-words', 'r').read().split()\n",
    "    df_fon['stopwords_removed'] = list(map(lambda doc:\n",
    "        [word for word in doc if word not in stopwords], df_fon['yorum']))\n",
    "remove_stopwords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verisetinde Positivity adlı bir sütunun oluşturalım ve başlangıçta tüm değerlere olumlu olarak 1 değerinin atayalım\n",
    "df['Positivity'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri setimizde 10003. veri ve sonrasındaki veriler olumsuz(negatif) verilerdir bu yüzden bu değerlerin\n",
    "#Positivity değerleri 0 ile değiştirelim.\n",
    "df.Positivity.iloc[10003:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13124     Film zaman geçirmek için iyi sayılabilir ama ...\n",
      "19649     kalitesi gerçekten düşük bir animasyon ayrıca...\n",
      "9846      filmi daha 2. gününde izledim ama yorum yapma...\n",
      "10800     şener şen'in oyunculuğu dışında hiç güzel değ...\n",
      "2733       Hayatımdaki yeri bambaşka olan bir film. 10/10 \n",
      "Name: yorum, dtype: object\n",
      "\n",
      "\n",
      "X_train shape:  (14999,)\n"
     ]
    }
   ],
   "source": [
    "#Şimdi, verileri \"yorum\" ve \"Positivity\" sütunlarını kullanarak rastgele eğitim ve test alt kümelerini bölüştürelim ve \n",
    "#ardından ilk girişi ve eğitim setinin şeklini yazalım.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['yorum'], df['Positivity'], random_state = 0)\n",
    "print(X_train.tail())\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer'ı başlatıyoruz ve eğitim verilerimize uyguluyoruz.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(encoding ='iso-8859-9').fit(X_train)\n",
    "\n",
    "#X_train'deki belgeleri bir belge terim matrisine dönüştürürüz\n",
    "X_train_vectorized = vect.transform(X_train) \n",
    "\n",
    "#Bu özellik matrisi X_ train_ vectorized'e dayanarak Lojistik Regresyon sınıflandırıcısını eğiteceğiz\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatif: \n",
      "['berbat' 'beğenmedim' 'sıkıcı' 'rezalet' 'vasat' 'değmez' 'gereksiz'\n",
      " 'sıkıldım' 'kötü' 'etmiyorum']\n",
      "\n",
      "Pozitif: \n",
      "['beğendim' 'mükemmel' 'müthiş' 'harika' 'söze' 'başyapıt' 'izlenmeli'\n",
      " 'zleyin' 'muhteşem' 'budur']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelimizin bu tahminleri nasıl yaptığını daha iyi anlamak için, her bir özellik için katsayıları (bir kelime), \n",
    "#pozitifliği ve olumsuzluk açısından ağırlığını belirlemek için kullanabiliriz.\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Negatif: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Pozitif: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8789689969970661\n",
      "En küçük Tfidf: \n",
      "['tazegül' 'durumla' 'isi' 'report' 'dönmesi' 'düşünme' 'öfke'\n",
      " 'karşımızdaki' 'oturan' 'kuzey']\n",
      "\n",
      "En büyük Tfidf: \n",
      "['basit' 'ben' 'etkileyici' 'vasat' 'cok' 'yorumsuz' 'izleyin' 'bence'\n",
      " 'erkek' 'sevmedim']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tf-idf vectorizer'ı başlatacağız ve eğitim verilerimize uygulayacağız. \n",
    "#En az beş dokümanda görünen kelime dağarcığımızdaki kelimeleri kaldıracağımız min_df = 5 değerini belirtiyoruz.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df = 5).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "a=roc_auc_score(y_test, predictions)\n",
    "print('AUC: ', a)  \n",
    "\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "print('En küçük Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('En büyük Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8761598679758971\n"
     ]
    }
   ],
   "source": [
    "#bigramlar, bitişik kelimelerin çiftlerini sayar ve bize kötü ve kötü olmayan gibi özellikler verebilir. \n",
    "#Bu nedenle, minimum 5 belge sıklığını belirten ve 1 gram ve 2 gram ekstrakt eden eğitim setimizi yeniden yerleştiriyoruz.\n",
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatif: \n",
      "['berbat' 'beğenmedim' 'rezalet' 'sıkıcı' 'en kötü' 'değmez' 'mahsun'\n",
      " 'gereksiz' 'vasat' 'yahudi']\n",
      "\n",
      "Pozitif: \n",
      "['10 10' 'mükemmel' 'beğendim' 'müthiş' 'filme kötü' 'harika' 'izlenmeli'\n",
      " 'rocky' 'başyapıt' 'budur']\n",
      "\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)berbat\n",
      "[0]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel değil\n",
      "[0]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)musluk\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)harika\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)mükemmel\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)dolap\n",
      "[1]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)rezalet\n",
      "[0]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)iyi değil\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Her özelliği kontrol etmek için katsayıları kullanarak görebiliriz\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Negatif: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n",
    "print('Pozitif: \\n{}\\n'.format(feature_names[sorted_coef_index][:-11:-1]))\n",
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model.predict(vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
